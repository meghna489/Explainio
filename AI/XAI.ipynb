{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xphS_q5sgU2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "def query_llama_api(prompt):\n",
    "    \"\"\"Generate response using Flan-T5 model.\"\"\"\n",
    "    model_name = \"google/flan-t5-large\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    # Add task prefix\n",
    "    formatted_prompt = f\"Answer the following question: {prompt}\"\n",
    "\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=500)  # Increase max tokens\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"Generated Output:\", generated_text)  # Debugging\n",
    "    return generated_text\n",
    "\n",
    "class SelfExplainableAI(nn.Module):\n",
    "    \"\"\"A simple self-explainable AI model using PyTorch.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SelfExplainableAI, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def explain_response(user_input):\n",
    "    \"\"\"AI generates a detailed and self-explanatory response.\"\"\"\n",
    "    reasoning_prompt = f\"Answer the following question and explain your reasoning step-by-step: {user_input}\"\n",
    "    response = query_llama_api(reasoning_prompt)\n",
    "\n",
    "    explanation = f\"The AI received the query: '{user_input}'.\\n\\n\"\n",
    "    explanation += f\"The AI used the following reasoning process:\\n{response}\\n\\n\"\n",
    "\n",
    "    return response + \"\\n\\n\" + explanation\n",
    "\n",
    "def chat():\n",
    "    \"\"\"Interactive chat function for user-friendly conversation.\"\"\"\n",
    "    print(\"\\nðŸ¤– AI Chatbot: Hello! Ask me anything, and I'll explain my answers in detail. Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"\\nðŸ¤– AI: Goodbye! Have a great day!\\n\")\n",
    "            break\n",
    "        response = explain_response(user_input)\n",
    "        print(\"\\nðŸ¤– AI:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ankit's Version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import re\n",
    "\n",
    "def query_llama_api(prompt):\n",
    "    \"\"\"Generate response using Flan-T5 model.\"\"\"\n",
    "    model_name = \"google/flan-t5-large\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    # Add task prefix\n",
    "    formatted_prompt = f\"Answer the following question: {prompt}\"\n",
    "\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=500)  # Increase max tokens\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"Generated Output:\", generated_text)  # Debugging\n",
    "    return generated_text\n",
    "\n",
    "def format_explanation(user_input, raw_explanation):\n",
    "    explanation = f\"ðŸ¤– AI Explanation for your query: '{user_input}'\\n\\n\"\n",
    "\n",
    "    # Basic attempt to structure using headings and bullet points\n",
    "    if \"explanation:\" in raw_explanation.lower() or \"reasoning:\" in raw_explanation.lower():\n",
    "        explanation += \"**Reasoning:**\\n\"\n",
    "        lines = raw_explanation.split('\\n')\n",
    "        in_reasoning = False\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if \"explanation:\" in line.lower() or \"reasoning:\" in line.lower():\n",
    "                in_reasoning = True\n",
    "                continue\n",
    "            if in_reasoning and line:\n",
    "                explanation += f\"- {line}\\n\"\n",
    "        if not any(re.search(r'^\\d+\\.', line) for line in lines): # Check for numbered lists\n",
    "            numbered_steps = [line for line in lines if re.match(r'Step \\d+:', line)]\n",
    "            if numbered_steps:\n",
    "                explanation = f\"ðŸ¤– AI Explanation for your query: '{user_input}'\\n\\n**Reasoning Steps:**\\n\"\n",
    "                for step in lines:\n",
    "                    if re.match(r'Step \\d+:', step):\n",
    "                        explanation += f\"- {step.strip()}\\n\"\n",
    "                    elif step.strip():\n",
    "                        explanation += f\"  - {step.strip()}\\n\" # Indent if not a direct step\n",
    "    else:\n",
    "        explanation += f\"The AI's explanation:\\n{raw_explanation}\\n\"\n",
    "\n",
    "    return explanation\n",
    "\n",
    "class SelfExplainableAI(nn.Module):\n",
    "    \"\"\"A simple self-explainable AI model using PyTorch.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SelfExplainableAI, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def explain_response(user_input):\n",
    "    reasoning_prompt = f\"Answer the following question and provide your explanation in a step-by-step format, using numbered lists:\\n\\nQuestion: {user_input}\\n\\nAnswer and Explanation:\"\n",
    "    raw_response = query_llama_api(reasoning_prompt)\n",
    "    explanation = format_explanation(user_input, raw_response) # We'll define this next\n",
    "    return explanation\n",
    "\n",
    "def chat():\n",
    "    \"\"\"Interactive chat function for user-friendly conversation.\"\"\"\n",
    "    print(\"\\nðŸ¤– AI Chatbot: Hello! Ask me anything, and I'll explain my answers in detail. Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"\\nðŸ¤– AI: Goodbye! Have a great day!\\n\")\n",
    "            break\n",
    "        response = explain_response(user_input)\n",
    "        print(\"\\nðŸ¤– AI:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import re\n",
    "\n",
    "def query_llama_api(prompt):\n",
    "    \"\"\"Generate response using Flan-T5 model.\"\"\"\n",
    "    model_name = \"google/flan-t5-large\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    formatted_prompt = f\"Answer the following question and provide your explanation in a step-by-step format, using numbered lists:\\n\\nQuestion: {prompt}\\n\\nAnswer and Explanation:\"\n",
    "\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=500)\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"Generated Output:\", generated_text)\n",
    "    return generated_text\n",
    "\n",
    "def format_explanation(user_input, raw_explanation):\n",
    "    explanation = f\"ðŸ¤– AI Explanation for your query: '{user_input}'\\n\\n\"\n",
    "\n",
    "    if raw_explanation:\n",
    "        lines = raw_explanation.strip().split('\\n')\n",
    "        in_explanation = False\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith(\"explanation:\") or line.lower().startswith(\"reasoning:\") or line.lower().startswith(\"step \"):\n",
    "                in_explanation = True\n",
    "                if line.lower().startswith(\"step \"):\n",
    "                    explanation += f\"- {line}\\n\"\n",
    "                elif not line.lower().startswith(\"explanation:\") and not line.lower().startswith(\"reasoning:\"):\n",
    "                    explanation += f\"**{line.capitalize()}**\\n\"\n",
    "            elif in_explanation and line:\n",
    "                if re.match(r'^\\d+\\.', line): # Check for numbered lists\n",
    "                    explanation += f\"- {line[line.find('.') + 1:].strip()}\\n\"\n",
    "                elif line.strip():\n",
    "                    explanation += f\"  - {line.strip()}\\n\" # Indent if not a direct step\n",
    "    else:\n",
    "        explanation += \"The AI could not generate an explanation.\"\n",
    "\n",
    "    return explanation\n",
    "\n",
    "def explain_response(user_input):\n",
    "    reasoning_prompt = f\"Answer the following question and provide your explanation in a step-by-step format, using numbered lists:\\n\\nQuestion: {user_input}\\n\\nAnswer and Explanation:\"\n",
    "    raw_response = query_llama_api(reasoning_prompt)\n",
    "    explanation = format_explanation(user_input, raw_response)\n",
    "    return explanation\n",
    "\n",
    "def chat():\n",
    "    print(\"\\nðŸ¤– AI Chatbot: Hello! Ask me anything, and I'll explain my answers in detail. Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"\\nðŸ¤– AI: Goodbye! Have a great day!\\n\")\n",
    "            break\n",
    "        response = explain_response(user_input)\n",
    "        print(\"\\nðŸ¤– AI:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ankit's Health Trained XAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/jupyter_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AI Chatbot: Hello! Ask me anything, and I'll explain my answers in detail. Type 'exit' to stop.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AI: ðŸ¤– AI Explanation for your query: 'What are the treatment options for Depression?'\n",
      "\n",
      "Explain the following question using the provided information, presented as a list with bullet points:\n",
      "\n",
      "Question: What are the treatment options for Depression?\n",
      "\n",
      "Relevant Information:\n",
      "Regarding Depression:\n",
      "\n",
      "**Treatment Pathways:**\n",
      "- Initial Intervention: Psychological counseling, Mild antidepressants, Lifestyle modification\n",
      "- Intensive Management: Combination therapy, Specialized psychiatric support, Comprehensive mental health program\n",
      "\n",
      "\n",
      "Explanation: The primary goal of this study was to determine whether depression is associated in any way or form (i.e., by its severity) and if it can be treated effectively through medication alone without further intervention from other treatments that may have been used prior to starting antidepressant medications on patients who were not depressed at baseline but had symptoms consistent throughout their lives after taking these drugs during adolescence/young adulthood.[1] This research has also shown an association between depressive symptomatology among adolescents aged 12â€“17 years[2], which suggests there might exist some underlying cause(s), such \"depression\" itself,[3][4]. However studies conducted over time suggest no clear link exists; however, many people do experience feelings of relief when they begin receiving SSRI's like Adderall [5],[6]; thus we believe our findings should provide additional evidence regarding how effective antihistamines could possibly become against mood disorders while still being safe enough even under controlled conditions where only mild side effects occur due simplyto lack thereof.(See below.)The main aim here would therefore likely involve understanding what causes individuals' experiences toward certain typesof bipolar disorder based upon clinical observations rather than anecdotal reports about them occurring within one year before initiating antipsychotic drug use themselvesâ€”and then determining why those same individual experienced similar levelsOf course I am aware that my own personal history does make me more susceptible towards various forms Of all things related To understand your situation you need to know something else You will probably want someone familiar With whom he knows well How much money He makes From his job As long ago as 2000+ Years old In fact most recently around 2005 It seems very unlikely That anyone ever saw him again After having taken several different antiepileptic medicines since childhood And now seeing myself every day For months At least once A few times Every week Or so Sometimes More Often But never Always Not Quite sure If anything Happened Before Starting Antidepressant Drugs On People Who Are Depressed They usually don't seem too concerned About getting better Treatment Options There appears little reason Why Some Patients Feel Better When Taking AntiDepressants While Others Don`t Have Any Concern Over Getting Worse Because Their Symptoms Arenï¿½nt So Bad...But Most Likely Those Experienced By Someone Else Is Differently AffectedBy Your Personal ExperienceYou'll Probably Need Somebody Like MeTo Understand My SituationI'm sorry though because sometimes just knowing somebody doesnÂ´re helpful! \n",
      "\n",
      "\n",
      "ðŸ¤– AI: Goodbye! Have a great day!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re\n",
    "import json\n",
    "\n",
    "# --- Health Dataset ---\n",
    "health_data = {\n",
    "    \"medical_conditions\": [\n",
    "        {\n",
    "            \"condition_id\": \"CHD001\",\n",
    "            \"name\": \"Coronary Heart Disease\",\n",
    "            \"risk_factors\": [\n",
    "                {\n",
    "                    \"factor\": \"High Cholesterol\",\n",
    "                    \"explanation\": \"Cholesterol buildup narrows arteries, reducing blood flow to heart\",\n",
    "                    \"impact_score\": 0.85,\n",
    "                    \"mitigation_strategies\": [\n",
    "                        \"Diet modification\",\n",
    "                        \"Statin medications\",\n",
    "                        \"Regular exercise\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"factor\": \"Obesity\",\n",
    "                    \"explanation\": \"Excess body weight increases strain on cardiovascular system\",\n",
    "                    \"impact_score\": 0.72,\n",
    "                    \"mitigation_strategies\": [\n",
    "                        \"Weight loss programs\",\n",
    "                        \"Nutritional counseling\",\n",
    "                        \"Physical activity\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"diagnostic_criteria\": {\n",
    "                \"tests\": [\n",
    "                    \"Cholesterol panel\",\n",
    "                    \"ECG\",\n",
    "                    \"Stress test\"\n",
    "                ],\n",
    "                \"diagnostic_thresholds\": {\n",
    "                    \"LDL_cholesterol\": \">160 mg/dL\",\n",
    "                    \"HDL_cholesterol\": \"<40 mg/dL\"\n",
    "                }\n",
    "            },\n",
    "            \"treatment_pathways\": [\n",
    "                {\n",
    "                    \"stage\": \"Early Intervention\",\n",
    "                    \"recommended_actions\": [\n",
    "                        \"Lifestyle modifications\",\n",
    "                        \"Medication management\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"stage\": \"Advanced Stage\",\n",
    "                    \"recommended_actions\": [\n",
    "                        \"Angioplasty\",\n",
    "                        \"Stent placement\",\n",
    "                        \"Bypass surgery\"\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"condition_id\": \"DIA002\",\n",
    "            \"name\": \"Type 2 Diabetes\",\n",
    "            \"risk_factors\": [\n",
    "                {\n",
    "                    \"factor\": \"Genetic Predisposition\",\n",
    "                    \"explanation\": \"Inherited genetic variations affect insulin production and sensitivity\",\n",
    "                    \"impact_score\": 0.65,\n",
    "                    \"mitigation_strategies\": [\n",
    "                        \"Regular screening\",\n",
    "                        \"Lifestyle modifications\",\n",
    "                        \"Genetic counseling\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"factor\": \"Sedentary Lifestyle\",\n",
    "                    \"explanation\": \"Lack of physical activity reduces insulin sensitivity\",\n",
    "                    \"impact_score\": 0.78,\n",
    "                    \"mitigation_strategies\": [\n",
    "                        \"Regular exercise\",\n",
    "                        \"Physical activity tracking\",\n",
    "                        \"Structured fitness programs\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"diagnostic_criteria\": {\n",
    "                \"tests\": [\n",
    "                    \"Fasting Blood Glucose\",\n",
    "                    \"HbA1c Test\",\n",
    "                    \"Oral Glucose Tolerance Test\"\n",
    "                ],\n",
    "                \"diagnostic_thresholds\": {\n",
    "                    \"fasting_glucose\": \">126 mg/dL\",\n",
    "                    \"HbA1c\": \">6.5%\"\n",
    "                }\n",
    "            },\n",
    "            \"treatment_pathways\": [\n",
    "                {\n",
    "                    \"stage\": \"Initial Management\",\n",
    "                    \"recommended_actions\": [\n",
    "                        \"Dietary counseling\",\n",
    "                        \"Metformin medication\",\n",
    "                        \"Blood glucose monitoring\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"stage\": \"Advanced Management\",\n",
    "                    \"recommended_actions\": [\n",
    "                        \"Insulin therapy\",\n",
    "                        \"Multiple medication approach\",\n",
    "                        \"Comprehensive metabolic management\"\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"condition_id\": \"MHD003\",\n",
    "            \"name\": \"Depression\",\n",
    "            \"risk_factors\": [\n",
    "                {\n",
    "                    \"factor\": \"Biochemical Imbalance\",\n",
    "                    \"explanation\": \"Neurotransmitter disruptions affecting mood regulation\",\n",
    "                    \"impact_score\": 0.70,\n",
    "                    \"mitigation_strategies\": [\n",
    "                        \"Antidepressant medication\",\n",
    "                        \"Neurotransmitter balancing techniques\",\n",
    "                        \"Psychological therapy\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"factor\": \"Chronic Stress\",\n",
    "                    \"explanation\": \"Prolonged stress impacts neurological and hormonal systems\",\n",
    "                    \"impact_score\": 0.75,\n",
    "                    \"mitigation_strategies\": [\n",
    "                        \"Stress management techniques\",\n",
    "                        \"Cognitive behavioral therapy\",\n",
    "                        \"Mindfulness practices\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"diagnostic_criteria\": {\n",
    "                \"assessment_tools\": [\n",
    "                    \"PHQ-9 Depression Screening\",\n",
    "                    \"Beck Depression Inventory\",\n",
    "                    \"Clinical psychiatric evaluation\"\n",
    "                ],\n",
    "                \"diagnostic_thresholds\": {\n",
    "                    \"PHQ9_score\": \">10\",\n",
    "                    \"symptom_duration\": \"2+ weeks\"\n",
    "                }\n",
    "            },\n",
    "            \"treatment_pathways\": [\n",
    "                {\n",
    "                    \"stage\": \"Initial Intervention\",\n",
    "                    \"recommended_actions\": [\n",
    "                        \"Psychological counseling\",\n",
    "                        \"Mild antidepressants\",\n",
    "                        \"Lifestyle modification\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"stage\": \"Intensive Management\",\n",
    "                    \"recommended_actions\": [\n",
    "                        \"Combination therapy\",\n",
    "                        \"Specialized psychiatric support\",\n",
    "                        \"Comprehensive mental health program\"\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"dataset_version\": \"1.0\",\n",
    "        \"last_updated\": \"2024-03-27\",\n",
    "        \"purpose\": \"Explainable AI Training in Healthcare\",\n",
    "        \"feature_focus\": [\n",
    "            \"Comprehensive Risk Assessment\",\n",
    "            \"Diagnostic Reasoning\",\n",
    "            \"Treatment Pathway Explanation\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "def query_llama_api(prompt, model_name=\"gpt2\"):\n",
    "    \"\"\"Generate response using a specified GPT model.\"\"\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs, max_length=1000, num_return_sequences=1, repetition_penalty=1.2) # Added repetition_penalty\n",
    "\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return generated_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or running model {model_name}: {e}\")\n",
    "        return \"Could not generate a response.\"\n",
    "\n",
    "def format_explanation(user_input, raw_explanation):\n",
    "    explanation = f\"ðŸ¤– AI Explanation for your query: '{user_input}'\\n\\n\"\n",
    "    if raw_explanation:\n",
    "        explanation += raw_explanation.strip()\n",
    "    else:\n",
    "        explanation += \"The AI could not generate an explanation.\"\n",
    "    return explanation\n",
    "\n",
    "def get_relevant_info(query, health_data):\n",
    "    query_lower = query.lower()\n",
    "    relevant_info = []\n",
    "\n",
    "    # Check for specific conditions\n",
    "    for condition in health_data[\"medical_conditions\"]:\n",
    "        if condition[\"name\"].lower() in query_lower:\n",
    "            relevant_info.append(f\"Regarding {condition['name']}:\")\n",
    "            # Include risk factors\n",
    "            if \"risk_factors\" in condition and any(rf[\"factor\"].lower() in query_lower for rf in condition[\"risk_factors\"]):\n",
    "                relevant_info.append(\"\\n**Risk Factors:**\")\n",
    "                for rf in condition[\"risk_factors\"]:\n",
    "                    if rf[\"factor\"].lower() in query_lower:\n",
    "                        relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "            # Include diagnostic criteria (simplified)\n",
    "            if \"diagnostic_criteria\" in condition and \"diagnose\" in query_lower:\n",
    "                tests = \", \".join(condition[\"diagnostic_criteria\"].get(\"tests\", []))\n",
    "                thresholds = \", \".join([f\"{k} {v}\" for k, v in condition[\"diagnostic_criteria\"].get(\"diagnostic_thresholds\", {}).items()])\n",
    "                if tests or thresholds:\n",
    "                    relevant_info.append(f\"\\n**Diagnosis:** It is diagnosed using tests like {tests} and thresholds such as {thresholds}.\")\n",
    "            # Include treatment pathways\n",
    "            if \"treatment_pathways\" in condition and \"treat\" in query_lower:\n",
    "                treatment_info = \"\\n**Treatment Pathways:**\\n\"\n",
    "                for stage in condition[\"treatment_pathways\"]:\n",
    "                    actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                    treatment_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                relevant_info.append(treatment_info)\n",
    "            break  # Assuming we want info about one condition at a time\n",
    "\n",
    "    # General questions about risk factors\n",
    "    if \"risk factors for\" in query_lower:\n",
    "        for condition in health_data[\"medical_conditions\"]:\n",
    "            if condition[\"name\"].lower() in query_lower:\n",
    "                relevant_info.append(f\"Risk factors for {condition['name']} include:\")\n",
    "                for rf in condition.get(\"risk_factors\", []):\n",
    "                    relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                break\n",
    "\n",
    "    return \"\\n\".join(relevant_info)\n",
    "\n",
    "def explain_response(user_input, health_data):\n",
    "    relevant_data = get_relevant_info(user_input, health_data)\n",
    "    if relevant_data:\n",
    "        prompt = f\"Explain the following question using the provided information, presented as a list with bullet points:\\n\\nQuestion: {user_input}\\n\\nRelevant Information:\\n{relevant_data}\\n\\nExplanation:\"\n",
    "    else:\n",
    "        prompt = f\"Explain the following question using bullet points:\\n\\nQuestion: {user_input}\\n\\nExplanation:\"\n",
    "\n",
    "    raw_response = query_llama_api(prompt, model_name=\"gpt2\") # Using gpt2\n",
    "    explanation = format_explanation(user_input, raw_response)\n",
    "    return explanation\n",
    "\n",
    "def chat():\n",
    "    print(\"\\nðŸ¤– AI Chatbot: Hello! Ask me anything, and I'll explain my answers in detail. Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"\\nðŸ¤– AI: Goodbye! Have a great day!\\n\")\n",
    "            break\n",
    "        response = explain_response(user_input, health_data)\n",
    "        print(\"\\nðŸ¤– AI:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM2vgOAZFEpKWBI4MY9NDTZ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
