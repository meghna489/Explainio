{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xphS_q5sgU2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "def query_llama_api(prompt):\n",
    "    \"\"\"Generate response using Flan-T5 model.\"\"\"\n",
    "    model_name = \"google/flan-t5-large\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    # Add task prefix\n",
    "    formatted_prompt = f\"Answer the following question: {prompt}\"\n",
    "\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=500)  # Increase max tokens\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"Generated Output:\", generated_text)  # Debugging\n",
    "    return generated_text\n",
    "\n",
    "class SelfExplainableAI(nn.Module):\n",
    "    \"\"\"A simple self-explainable AI model using PyTorch.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SelfExplainableAI, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def explain_response(user_input):\n",
    "    \"\"\"AI generates a detailed and self-explanatory response.\"\"\"\n",
    "    reasoning_prompt = f\"Answer the following question and explain your reasoning step-by-step: {user_input}\"\n",
    "    response = query_llama_api(reasoning_prompt)\n",
    "\n",
    "    explanation = f\"The AI received the query: '{user_input}'.\\n\\n\"\n",
    "    explanation += f\"The AI used the following reasoning process:\\n{response}\\n\\n\"\n",
    "\n",
    "    return response + \"\\n\\n\" + explanation\n",
    "\n",
    "def chat():\n",
    "    \"\"\"Interactive chat function for user-friendly conversation.\"\"\"\n",
    "    print(\"\\nðŸ¤– AI Chatbot: Hello! Ask me anything, and I'll explain my answers in detail. Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"\\nðŸ¤– AI: Goodbye! Have a great day!\\n\")\n",
    "            break\n",
    "        response = explain_response(user_input)\n",
    "        print(\"\\nðŸ¤– AI:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ankit's Version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import re\n",
    "\n",
    "def query_llama_api(prompt):\n",
    "    \"\"\"Generate response using Flan-T5 model.\"\"\"\n",
    "    model_name = \"google/flan-t5-large\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    # Add task prefix\n",
    "    formatted_prompt = f\"Answer the following question: {prompt}\"\n",
    "\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=500)  # Increase max tokens\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"Generated Output:\", generated_text)  # Debugging\n",
    "    return generated_text\n",
    "\n",
    "def format_explanation(user_input, raw_explanation):\n",
    "    explanation = f\"ðŸ¤– AI Explanation for your query: '{user_input}'\\n\\n\"\n",
    "\n",
    "    # Basic attempt to structure using headings and bullet points\n",
    "    if \"explanation:\" in raw_explanation.lower() or \"reasoning:\" in raw_explanation.lower():\n",
    "        explanation += \"**Reasoning:**\\n\"\n",
    "        lines = raw_explanation.split('\\n')\n",
    "        in_reasoning = False\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if \"explanation:\" in line.lower() or \"reasoning:\" in line.lower():\n",
    "                in_reasoning = True\n",
    "                continue\n",
    "            if in_reasoning and line:\n",
    "                explanation += f\"- {line}\\n\"\n",
    "        if not any(re.search(r'^\\d+\\.', line) for line in lines): # Check for numbered lists\n",
    "            numbered_steps = [line for line in lines if re.match(r'Step \\d+:', line)]\n",
    "            if numbered_steps:\n",
    "                explanation = f\"ðŸ¤– AI Explanation for your query: '{user_input}'\\n\\n**Reasoning Steps:**\\n\"\n",
    "                for step in lines:\n",
    "                    if re.match(r'Step \\d+:', step):\n",
    "                        explanation += f\"- {step.strip()}\\n\"\n",
    "                    elif step.strip():\n",
    "                        explanation += f\"  - {step.strip()}\\n\" # Indent if not a direct step\n",
    "    else:\n",
    "        explanation += f\"The AI's explanation:\\n{raw_explanation}\\n\"\n",
    "\n",
    "    return explanation\n",
    "\n",
    "class SelfExplainableAI(nn.Module):\n",
    "    \"\"\"A simple self-explainable AI model using PyTorch.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SelfExplainableAI, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def explain_response(user_input):\n",
    "    reasoning_prompt = f\"Answer the following question and provide your explanation in a step-by-step format, using numbered lists:\\n\\nQuestion: {user_input}\\n\\nAnswer and Explanation:\"\n",
    "    raw_response = query_llama_api(reasoning_prompt)\n",
    "    explanation = format_explanation(user_input, raw_response) # We'll define this next\n",
    "    return explanation\n",
    "\n",
    "def chat():\n",
    "    \"\"\"Interactive chat function for user-friendly conversation.\"\"\"\n",
    "    print(\"\\nðŸ¤– AI Chatbot: Hello! Ask me anything, and I'll explain my answers in detail. Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"\\nðŸ¤– AI: Goodbye! Have a great day!\\n\")\n",
    "            break\n",
    "        response = explain_response(user_input)\n",
    "        print(\"\\nðŸ¤– AI:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import re\n",
    "\n",
    "def query_llama_api(prompt):\n",
    "    \"\"\"Generate response using Flan-T5 model.\"\"\"\n",
    "    model_name = \"google/flan-t5-large\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    formatted_prompt = f\"Answer the following question and provide your explanation in a step-by-step format, using numbered lists:\\n\\nQuestion: {prompt}\\n\\nAnswer and Explanation:\"\n",
    "\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=500)\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"Generated Output:\", generated_text)\n",
    "    return generated_text\n",
    "\n",
    "def format_explanation(user_input, raw_explanation):\n",
    "    explanation = f\"ðŸ¤– AI Explanation for your query: '{user_input}'\\n\\n\"\n",
    "\n",
    "    if raw_explanation:\n",
    "        lines = raw_explanation.strip().split('\\n')\n",
    "        in_explanation = False\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith(\"explanation:\") or line.lower().startswith(\"reasoning:\") or line.lower().startswith(\"step \"):\n",
    "                in_explanation = True\n",
    "                if line.lower().startswith(\"step \"):\n",
    "                    explanation += f\"- {line}\\n\"\n",
    "                elif not line.lower().startswith(\"explanation:\") and not line.lower().startswith(\"reasoning:\"):\n",
    "                    explanation += f\"**{line.capitalize()}**\\n\"\n",
    "            elif in_explanation and line:\n",
    "                if re.match(r'^\\d+\\.', line): # Check for numbered lists\n",
    "                    explanation += f\"- {line[line.find('.') + 1:].strip()}\\n\"\n",
    "                elif line.strip():\n",
    "                    explanation += f\"  - {line.strip()}\\n\" # Indent if not a direct step\n",
    "    else:\n",
    "        explanation += \"The AI could not generate an explanation.\"\n",
    "\n",
    "    return explanation\n",
    "\n",
    "def explain_response(user_input):\n",
    "    reasoning_prompt = f\"Answer the following question and provide your explanation in a step-by-step format, using numbered lists:\\n\\nQuestion: {user_input}\\n\\nAnswer and Explanation:\"\n",
    "    raw_response = query_llama_api(reasoning_prompt)\n",
    "    explanation = format_explanation(user_input, raw_response)\n",
    "    return explanation\n",
    "\n",
    "def chat():\n",
    "    print(\"\\nðŸ¤– AI Chatbot: Hello! Ask me anything, and I'll explain my answers in detail. Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"\\nðŸ¤– AI: Goodbye! Have a great day!\\n\")\n",
    "            break\n",
    "        response = explain_response(user_input)\n",
    "        print(\"\\nðŸ¤– AI:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ankit's Health Trained XAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/jupyter_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AI Chatbot: Hello! Ask me anything, and I'll explain my answers in detail. Type 'exit' to stop.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AI: ðŸ¤– AI Explanation for your query: 'What are the treatment options for Depression?'\n",
      "\n",
      "Explain the following question using the provided information, presented as a list with bullet points:\n",
      "\n",
      "Question: What are the treatment options for Depression?\n",
      "\n",
      "Relevant Information:\n",
      "Regarding Depression:\n",
      "\n",
      "**Treatment Pathways:**\n",
      "- Initial Intervention: Psychological counseling, Mild antidepressants, Lifestyle modification\n",
      "- Intensive Management: Combination therapy, Specialized psychiatric support, Comprehensive mental health program\n",
      "\n",
      "\n",
      "Explanation: The primary goal of this study was to determine whether depression is associated in any way or form (i.e., by its severity) and if it can be treated effectively through medication alone without further intervention from other treatments that may have been used prior to starting antidepressant medications on patients who were not depressed at baseline but had symptoms consistent throughout their lives after taking these drugs during adolescence/young adulthood.[1] This research has also shown an association between depressive symptomatology among adolescents aged 12â€“17 years[2], which suggests there might exist some underlying cause(s), such \"depression\" itself,[3][4]. However studies conducted over time suggest no clear link exists; however, many people do experience feelings of relief when they begin receiving SSRI's like Adderall [5],[6]; thus we believe our findings should provide additional evidence regarding how effective antihistamines could possibly become against mood disorders while still being safe enough even under controlled conditions where only mild side effects occur due simplyto lack thereof.(See below.)The main aim here would therefore likely involve understanding what causes individuals' experiences toward certain typesof bipolar disorder based upon clinical observations rather than anecdotal reports about them occurring within one year before initiating antipsychotic drug use themselvesâ€”and then determining why those same individual experienced similar levelsOf course I am aware that my own personal history does make me more susceptible towards various forms Of all things related To understand your situation you need to know something else You will probably want someone familiar With whom he knows well How much money He makes From his job As long ago as 2000+ Years old In fact most recently around 2005 It seems very unlikely That anyone ever saw him again After having taken several different antiepileptic medicines since childhood And now seeing myself every day For months At least once A few times Every week Or so Sometimes More Often But never Always Not Quite sure If anything Happened Before Starting Antidepressant Drugs On People Who Are Depressed They usually don't seem too concerned About getting better Treatment Options There appears little reason Why Some Patients Feel Better When Taking AntiDepressants While Others Don`t Have Any Concern Over Getting Worse Because Their Symptoms Arenï¿½nt So Bad...But Most Likely Those Experienced By Someone Else Is Differently AffectedBy Your Personal ExperienceYou'll Probably Need Somebody Like MeTo Understand My SituationI'm sorry though because sometimes just knowing somebody doesnÂ´re helpful! \n",
      "\n",
      "\n",
      "ðŸ¤– AI: Goodbye! Have a great day!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re\n",
    "import json\n",
    "\n",
    "# --- Health Dataset ---\n",
    "health_data = {\n",
    "    \"medical_conditions\": [\n",
    "        {\n",
    "            \"condition_id\": \"CHD001\",\n",
    "            \"name\": \"Coronary Heart Disease\",\n",
    "            \"risk_factors\": [\n",
    "                {\n",
    "                    \"factor\": \"High Cholesterol\",\n",
    "                    \"explanation\": \"Cholesterol buildup narrows arteries, reducing blood flow to heart\",\n",
    "                    \"impact_score\": 0.85,\n",
    "                    \"mitigation_strategies\": [\n",
    "                        \"Diet modification\",\n",
    "                        \"Statin medications\",\n",
    "                        \"Regular exercise\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"factor\": \"Obesity\",\n",
    "                    \"explanation\": \"Excess body weight increases strain on cardiovascular system\",\n",
    "                    \"impact_score\": 0.72,\n",
    "                    \"mitigation_strategies\": [\n",
    "                        \"Weight loss programs\",\n",
    "                        \"Nutritional counseling\",\n",
    "                        \"Physical activity\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"diagnostic_criteria\": {\n",
    "                \"tests\": [\n",
    "                    \"Cholesterol panel\",\n",
    "                    \"ECG\",\n",
    "                    \"Stress test\"\n",
    "                ],\n",
    "                \"diagnostic_thresholds\": {\n",
    "                    \"LDL_cholesterol\": \">160 mg/dL\",\n",
    "                    \"HDL_cholesterol\": \"<40 mg/dL\"\n",
    "                }\n",
    "            },\n",
    "            \"treatment_pathways\": [\n",
    "                {\n",
    "                    \"stage\": \"Early Intervention\",\n",
    "                    \"recommended_actions\": [\n",
    "                        \"Lifestyle modifications\",\n",
    "                        \"Medication management\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"stage\": \"Advanced Stage\",\n",
    "                    \"recommended_actions\": [\n",
    "                        \"Angioplasty\",\n",
    "                        \"Stent placement\",\n",
    "                        \"Bypass surgery\"\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"condition_id\": \"DIA002\",\n",
    "            \"name\": \"Type 2 Diabetes\",\n",
    "            \"risk_factors\": [\n",
    "                {\n",
    "                    \"factor\": \"Genetic Predisposition\",\n",
    "                    \"explanation\": \"Inherited genetic variations affect insulin production and sensitivity\",\n",
    "                    \"impact_score\": 0.65,\n",
    "                    \"mitigation_strategies\": [\n",
    "                        \"Regular screening\",\n",
    "                        \"Lifestyle modifications\",\n",
    "                        \"Genetic counseling\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"factor\": \"Sedentary Lifestyle\",\n",
    "                    \"explanation\": \"Lack of physical activity reduces insulin sensitivity\",\n",
    "                    \"impact_score\": 0.78,\n",
    "                    \"mitigation_strategies\": [\n",
    "                        \"Regular exercise\",\n",
    "                        \"Physical activity tracking\",\n",
    "                        \"Structured fitness programs\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"diagnostic_criteria\": {\n",
    "                \"tests\": [\n",
    "                    \"Fasting Blood Glucose\",\n",
    "                    \"HbA1c Test\",\n",
    "                    \"Oral Glucose Tolerance Test\"\n",
    "                ],\n",
    "                \"diagnostic_thresholds\": {\n",
    "                    \"fasting_glucose\": \">126 mg/dL\",\n",
    "                    \"HbA1c\": \">6.5%\"\n",
    "                }\n",
    "            },\n",
    "            \"treatment_pathways\": [\n",
    "                {\n",
    "                    \"stage\": \"Initial Management\",\n",
    "                    \"recommended_actions\": [\n",
    "                        \"Dietary counseling\",\n",
    "                        \"Metformin medication\",\n",
    "                        \"Blood glucose monitoring\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"stage\": \"Advanced Management\",\n",
    "                    \"recommended_actions\": [\n",
    "                        \"Insulin therapy\",\n",
    "                        \"Multiple medication approach\",\n",
    "                        \"Comprehensive metabolic management\"\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"condition_id\": \"MHD003\",\n",
    "            \"name\": \"Depression\",\n",
    "            \"risk_factors\": [\n",
    "                {\n",
    "                    \"factor\": \"Biochemical Imbalance\",\n",
    "                    \"explanation\": \"Neurotransmitter disruptions affecting mood regulation\",\n",
    "                    \"impact_score\": 0.70,\n",
    "                    \"mitigation_strategies\": [\n",
    "                        \"Antidepressant medication\",\n",
    "                        \"Neurotransmitter balancing techniques\",\n",
    "                        \"Psychological therapy\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"factor\": \"Chronic Stress\",\n",
    "                    \"explanation\": \"Prolonged stress impacts neurological and hormonal systems\",\n",
    "                    \"impact_score\": 0.75,\n",
    "                    \"mitigation_strategies\": [\n",
    "                        \"Stress management techniques\",\n",
    "                        \"Cognitive behavioral therapy\",\n",
    "                        \"Mindfulness practices\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"diagnostic_criteria\": {\n",
    "                \"assessment_tools\": [\n",
    "                    \"PHQ-9 Depression Screening\",\n",
    "                    \"Beck Depression Inventory\",\n",
    "                    \"Clinical psychiatric evaluation\"\n",
    "                ],\n",
    "                \"diagnostic_thresholds\": {\n",
    "                    \"PHQ9_score\": \">10\",\n",
    "                    \"symptom_duration\": \"2+ weeks\"\n",
    "                }\n",
    "            },\n",
    "            \"treatment_pathways\": [\n",
    "                {\n",
    "                    \"stage\": \"Initial Intervention\",\n",
    "                    \"recommended_actions\": [\n",
    "                        \"Psychological counseling\",\n",
    "                        \"Mild antidepressants\",\n",
    "                        \"Lifestyle modification\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"stage\": \"Intensive Management\",\n",
    "                    \"recommended_actions\": [\n",
    "                        \"Combination therapy\",\n",
    "                        \"Specialized psychiatric support\",\n",
    "                        \"Comprehensive mental health program\"\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"dataset_version\": \"1.0\",\n",
    "        \"last_updated\": \"2024-03-27\",\n",
    "        \"purpose\": \"Explainable AI Training in Healthcare\",\n",
    "        \"feature_focus\": [\n",
    "            \"Comprehensive Risk Assessment\",\n",
    "            \"Diagnostic Reasoning\",\n",
    "            \"Treatment Pathway Explanation\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "def query_llama_api(prompt, model_name=\"gpt2\"):\n",
    "    \"\"\"Generate response using a specified GPT model.\"\"\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs, max_length=1000, num_return_sequences=1, repetition_penalty=1.2) # Added repetition_penalty\n",
    "\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return generated_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or running model {model_name}: {e}\")\n",
    "        return \"Could not generate a response.\"\n",
    "\n",
    "def format_explanation(user_input, raw_explanation):\n",
    "    explanation = f\"ðŸ¤– AI Explanation for your query: '{user_input}'\\n\\n\"\n",
    "    if raw_explanation:\n",
    "        explanation += raw_explanation.strip()\n",
    "    else:\n",
    "        explanation += \"The AI could not generate an explanation.\"\n",
    "    return explanation\n",
    "\n",
    "def get_relevant_info(query, health_data):\n",
    "    query_lower = query.lower()\n",
    "    relevant_info = []\n",
    "\n",
    "    # Check for specific conditions\n",
    "    for condition in health_data[\"medical_conditions\"]:\n",
    "        if condition[\"name\"].lower() in query_lower:\n",
    "            relevant_info.append(f\"Regarding {condition['name']}:\")\n",
    "            # Include risk factors\n",
    "            if \"risk_factors\" in condition and any(rf[\"factor\"].lower() in query_lower for rf in condition[\"risk_factors\"]):\n",
    "                relevant_info.append(\"\\n**Risk Factors:**\")\n",
    "                for rf in condition[\"risk_factors\"]:\n",
    "                    if rf[\"factor\"].lower() in query_lower:\n",
    "                        relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "            # Include diagnostic criteria (simplified)\n",
    "            if \"diagnostic_criteria\" in condition and \"diagnose\" in query_lower:\n",
    "                tests = \", \".join(condition[\"diagnostic_criteria\"].get(\"tests\", []))\n",
    "                thresholds = \", \".join([f\"{k} {v}\" for k, v in condition[\"diagnostic_criteria\"].get(\"diagnostic_thresholds\", {}).items()])\n",
    "                if tests or thresholds:\n",
    "                    relevant_info.append(f\"\\n**Diagnosis:** It is diagnosed using tests like {tests} and thresholds such as {thresholds}.\")\n",
    "            # Include treatment pathways\n",
    "            if \"treatment_pathways\" in condition and \"treat\" in query_lower:\n",
    "                treatment_info = \"\\n**Treatment Pathways:**\\n\"\n",
    "                for stage in condition[\"treatment_pathways\"]:\n",
    "                    actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                    treatment_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                relevant_info.append(treatment_info)\n",
    "            break  # Assuming we want info about one condition at a time\n",
    "\n",
    "    # General questions about risk factors\n",
    "    if \"risk factors for\" in query_lower:\n",
    "        for condition in health_data[\"medical_conditions\"]:\n",
    "            if condition[\"name\"].lower() in query_lower:\n",
    "                relevant_info.append(f\"Risk factors for {condition['name']} include:\")\n",
    "                for rf in condition.get(\"risk_factors\", []):\n",
    "                    relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                break\n",
    "\n",
    "    return \"\\n\".join(relevant_info)\n",
    "\n",
    "def explain_response(user_input, health_data):\n",
    "    relevant_data = get_relevant_info(user_input, health_data)\n",
    "    if relevant_data:\n",
    "        prompt = f\"Explain the following question using the provided information, presented as a list with bullet points:\\n\\nQuestion: {user_input}\\n\\nRelevant Information:\\n{relevant_data}\\n\\nExplanation:\"\n",
    "    else:\n",
    "        prompt = f\"Explain the following question using bullet points:\\n\\nQuestion: {user_input}\\n\\nExplanation:\"\n",
    "\n",
    "    raw_response = query_llama_api(prompt, model_name=\"gpt2\") # Using gpt2\n",
    "    explanation = format_explanation(user_input, raw_response)\n",
    "    return explanation\n",
    "\n",
    "def chat():\n",
    "    print(\"\\nðŸ¤– AI Chatbot: Hello! Ask me anything, and I'll explain my answers in detail. Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"\\nðŸ¤– AI: Goodbye! Have a great day!\\n\")\n",
    "            break\n",
    "        response = explain_response(user_input, health_data)\n",
    "        print(\"\\nðŸ¤– AI:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding fitness,career and relationship datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AI Chatbot: Hello! Ask me anything about health, career, relationships, or fitness, and I'll explain my answers in detail. Type 'exit' to stop.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AI: ðŸ¤– AI Explanation for your query: 'What skills do I need to learn or improve to advance in my career?'\n",
      "\n",
      "Explain the following question using bullet points:\n",
      "\n",
      "Question: What skills do I need to learn or improve to advance in my career?\n",
      "\n",
      "Explanation: The answer is simple. You can't just pick up a gun and shoot people, you have to be able for yourself not only how to use it but also what kind of weapon that will work best with your situation (e-mailing me if there are any questions). If someone asks about \"how to get into an armed robbery\" then they're going too far; this isn't really relevant here because we don`re talking about guns right now so let's talk more on firearms first! \n",
      "\n",
      "\n",
      "ðŸ¤– AI: Goodbye! Have a great day!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re\n",
    "import json\n",
    "\n",
    "# --- Load JSON Datasets ---\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "health_data = load_json('health_data.json')\n",
    "career_data = load_json('career_data.json')\n",
    "relationship_data = load_json('relationship_data.json')\n",
    "fitness_data = load_json('fitness_data.json')\n",
    "\n",
    "all_data = {\n",
    "    \"health\": health_data,\n",
    "    \"career\": career_data,\n",
    "    \"relationship\": relationship_data,\n",
    "    \"fitness\": fitness_data\n",
    "}\n",
    "\n",
    "def query_llama_api(prompt, model_name=\"gpt2\"):\n",
    "    \"\"\"Generate response using a specified GPT model.\"\"\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs, max_length=1000, num_return_sequences=1, repetition_penalty=1.2) # Added repetition_penalty\n",
    "\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return generated_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or running model {model_name}: {e}\")\n",
    "        return \"Could not generate a response.\"\n",
    "\n",
    "def format_explanation(user_input, raw_explanation):\n",
    "    explanation = f\"ðŸ¤– AI Explanation for your query: '{user_input}'\\n\\n\"\n",
    "    if raw_explanation:\n",
    "        explanation += raw_explanation.strip()\n",
    "    else:\n",
    "        explanation += \"The AI could not generate an explanation.\"\n",
    "    return explanation\n",
    "\n",
    "def get_relevant_info_all(query, all_data):\n",
    "    query_lower = query.lower()\n",
    "    relevant_info = []\n",
    "\n",
    "    for category, data in all_data.items():\n",
    "        if category == \"health\":\n",
    "            # Check for specific conditions\n",
    "            for condition in data[\"medical_conditions\"]:\n",
    "                if condition[\"name\"].lower() in query_lower:\n",
    "                    relevant_info.append(f\"Regarding {condition['name']} (Health):\")\n",
    "                    # Include risk factors\n",
    "                    if \"risk_factors\" in condition and any(rf[\"factor\"].lower() in query_lower for rf in condition[\"risk_factors\"]):\n",
    "                        relevant_info.append(\"\\n**Risk Factors:**\")\n",
    "                        for rf in condition[\"risk_factors\"]:\n",
    "                            if rf[\"factor\"].lower() in query_lower:\n",
    "                                relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                    # Include diagnostic criteria (simplified)\n",
    "                    if \"diagnostic_criteria\" in condition and \"diagnose\" in query_lower:\n",
    "                        tests = \", \".join(condition[\"diagnostic_criteria\"].get(\"tests\", []))\n",
    "                        thresholds = \", \".join([f\"{k} {v}\" for k, v in condition[\"diagnostic_criteria\"].get(\"diagnostic_thresholds\", {}).items()])\n",
    "                        if tests or thresholds:\n",
    "                            relevant_info.append(f\"\\n**Diagnosis:** It is diagnosed using tests like {tests} and thresholds such as {thresholds}.\")\n",
    "                    # Include treatment pathways\n",
    "                    if \"treatment_pathways\" in condition and \"treat\" in query_lower:\n",
    "                        treatment_info = \"\\n**Treatment Pathways:**\\n\"\n",
    "                        for stage in condition[\"treatment_pathways\"]:\n",
    "                            actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                            treatment_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                        relevant_info.append(treatment_info)\n",
    "                    break  # Assuming we want info about one condition at a time\n",
    "\n",
    "            # General questions about risk factors\n",
    "            if \"risk factors for\" in query_lower:\n",
    "                for condition in data[\"medical_conditions\"]:\n",
    "                    if condition[\"name\"].lower() in query_lower:\n",
    "                        relevant_info.append(f\"Risk factors for {condition['name']} (Health) include:\")\n",
    "                        for rf in condition.get(\"risk_factors\", []):\n",
    "                            relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                        break\n",
    "\n",
    "        elif category == \"career\":\n",
    "            # Check for specific career opportunities\n",
    "            for career in data[\"career_opportunities\"]:\n",
    "                if career[\"name\"].lower() in query_lower:\n",
    "                    relevant_info.append(f\"Regarding {career['name']} (Career):\")\n",
    "                    # Include career pathways\n",
    "                    if \"career_pathways\" in career and \"pathways\" in query_lower:\n",
    "                        relevant_info.append(\"\\n**Career Pathways:**\")\n",
    "                        for cp in career[\"career_pathways\"]:\n",
    "                            relevant_info.append(f\"- {cp['factor']}: {cp['explanation']}\")\n",
    "                    # Include entry requirements\n",
    "                    if \"entry requirements\" in query_lower or \"requirements for\" in query_lower:\n",
    "                        if \"career_progression_criteria\" in career and \"entry_requirements\" in career[\"career_progression_criteria\"]:\n",
    "                            requirements = \", \".join(career[\"career_progression_criteria\"][\"entry_requirements\"])\n",
    "                            relevant_info.append(f\"\\n**Entry Requirements:** {requirements}\")\n",
    "                    # Include advancement pathways\n",
    "                    if \"advancement\" in query_lower or \"progression\" in query_lower:\n",
    "                        if \"advancement_pathways\" in career:\n",
    "                            advancement_info = \"\\n**Advancement Pathways:**\\n\"\n",
    "                            for stage in career[\"advancement_pathways\"]:\n",
    "                                actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                                advancement_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                            relevant_info.append(advancement_info)\n",
    "                    break\n",
    "\n",
    "        elif category == \"relationship\":\n",
    "            # Check for specific relationship types\n",
    "            for relationship in data[\"relationship_types\"]:\n",
    "                if relationship[\"name\"].lower() in query_lower:\n",
    "                    relevant_info.append(f\"Regarding {relationship['name']} (Relationship):\")\n",
    "                    # Include relationship factors\n",
    "                    if \"relationship_factors\" in relationship and \"factors\" in query_lower:\n",
    "                        relevant_info.append(\"\\n**Relationship Factors:**\")\n",
    "                        for rf in relationship[\"relationship_factors\"]:\n",
    "                            relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                    # Include development pathways\n",
    "                    if \"development\" in query_lower or \"building\" in query_lower:\n",
    "                        if \"relationship_development_pathways\" in relationship:\n",
    "                            development_info = \"\\n**Development Pathways:**\\n\"\n",
    "                            for stage in relationship[\"relationship_development_pathways\"]:\n",
    "                                actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                                development_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                            relevant_info.append(development_info)\n",
    "                    break\n",
    "\n",
    "        elif category == \"fitness\":\n",
    "            # Check for specific fitness questions\n",
    "            if \"fitness_data\" in data:  # Check if \"fitness_data\" key exists\n",
    "                for item in data[\"fitness_data\"]:  # Iterate through the array\n",
    "                    if item[\"question\"].lower() in query_lower:\n",
    "                        relevant_info.append(f\"Regarding {item['question']} (Fitness):\")\n",
    "                        # Include explanation\n",
    "                        if \"explanation\" in item:\n",
    "                            relevant_info.append(f\"\\n**Explanation:** {item['explanation']}\")\n",
    "                        # Include additional details\n",
    "                        if \"additional_details\" in item:\n",
    "                            relevant_info.append(\"\\n**Additional Details:**\")\n",
    "                            for key, value in item[\"additional_details\"].items():\n",
    "                                if isinstance(value, list):\n",
    "                                    relevant_info.append(f\"\\n{key.capitalize()}:\")\n",
    "                                    for detail in value:\n",
    "                                        if isinstance(detail, dict):\n",
    "                                            for sub_key, sub_value in detail.items():\n",
    "                                                relevant_info.append(f\"- {sub_key.capitalize()}: {sub_value}\")\n",
    "                                        else:\n",
    "                                            relevant_info.append(f\"- {detail}\")\n",
    "                                else:\n",
    "                                    relevant_info.append(f\"\\n{key.capitalize()}: {value}\")\n",
    "                        break\n",
    "\n",
    "    return \"\\n\".join(relevant_info)\n",
    "\n",
    "def explain_response_all(user_input, all_data):\n",
    "    relevant_data = get_relevant_info_all(user_input, all_data)\n",
    "    if relevant_data:\n",
    "        prompt = f\"Explain the following question using the provided information, presented as a list with bullet points:\\n\\nQuestion: {user_input}\\n\\nRelevant Information:\\n{relevant_data}\\n\\nExplanation:\"\n",
    "    else:\n",
    "        prompt = f\"Explain the following question using bullet points:\\n\\nQuestion: {user_input}\\n\\nExplanation:\"\n",
    "\n",
    "    raw_response = query_llama_api(prompt, model_name=\"gpt2\") # Using gpt2\n",
    "    explanation = format_explanation(user_input, raw_response)\n",
    "    return explanation\n",
    "\n",
    "def chat():\n",
    "    print(\"\\nðŸ¤– AI Chatbot: Hello! Ask me anything about health, career, relationships, or fitness, and I'll explain my answers in detail. Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"\\nðŸ¤– AI: Goodbye! Have a great day!\\n\")\n",
    "            break\n",
    "        response = explain_response_all(user_input, all_data)\n",
    "        print(\"\\nðŸ¤– AI:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing model to gemini flash-2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"/Users/ankittalukder/.config/gcloud/application_default_credentials.json\"\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_APPLICATION_CREDENTIALS=\"/Users/ankittalukder/.config/gcloud/application_default_credentials.json\"\n"
     ]
    }
   ],
   "source": [
    "%env GOOGLE_APPLICATION_CREDENTIALS=\"/Users/ankittalukder/.config/gcloud/application_default_credentials.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AI Chatbot: Hello! Ask me anything about health, career, relationships, or fitness, and I'll explain my answers in detail. Type 'exit' to stop.\n",
      "\n",
      "Error loading or running Llama 2: You are trying to access a gated repo.\n",
      "Make sure to have access to it at https://huggingface.co/meta-llama/Llama-2-7b-chat-hf.\n",
      "401 Client Error. (Request ID: Root=1-67e61e9e-1048403e73730c744fee5099;e3056f2b-082e-4c79-8f49-5ec07cee89cf)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/config.json.\n",
      "Access to model meta-llama/Llama-2-7b-chat-hf is restricted. You must have access to it and be authenticated to access it. Please log in.\n",
      "\n",
      "ðŸ¤– AI: ðŸ¤– AI Explanation for your query: 'What skills do I need to learn or improve to advance in my career?'\n",
      "\n",
      "Could not generate a response. \n",
      "\n",
      "\n",
      "ðŸ¤– AI: Goodbye! Have a great day!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "\n",
    "# --- Load JSON Datasets ---\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "health_data = load_json('health_data.json')\n",
    "career_data = load_json('career_data.json')\n",
    "relationship_data = load_json('relationship_data.json')\n",
    "fitness_data = load_json('fitness_data.json')\n",
    "\n",
    "all_data = {\n",
    "    \"health\": health_data,\n",
    "    \"career\": career_data,\n",
    "    \"relationship\": relationship_data,\n",
    "    \"fitness\": fitness_data\n",
    "}\n",
    "\n",
    "# --- Llama 2 API Integration ---\n",
    "def query_llama_2_api(prompt, model_name=\"meta-llama/Llama-2-7b-chat-hf\"):\n",
    "    \"\"\"Generate response using Llama 2 with 4-bit quantization.\"\"\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            load_in_4bit=True,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        outputs = model.generate(**inputs, max_length=1000)\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or running Llama 2: {e}\")\n",
    "        return \"Could not generate a response.\"\n",
    "\n",
    "def format_explanation(user_input, raw_explanation):\n",
    "    explanation = f\"ðŸ¤– AI Explanation for your query: '{user_input}'\\n\\n\"\n",
    "    if raw_explanation:\n",
    "        explanation += raw_explanation.strip()\n",
    "    else:\n",
    "        explanation += \"The AI could not generate an explanation.\"\n",
    "    return explanation\n",
    "\n",
    "def get_relevant_info_all(query, all_data):\n",
    "    query_lower = query.lower()\n",
    "    relevant_info = []\n",
    "\n",
    "    for category, data in all_data.items():\n",
    "        if category == \"health\":\n",
    "            # Check for specific conditions\n",
    "            for condition in data[\"medical_conditions\"]:\n",
    "                if condition[\"name\"].lower() in query_lower:\n",
    "                    relevant_info.append(f\"Regarding {condition['name']} (Health):\")\n",
    "                    # Include risk factors\n",
    "                    if \"risk_factors\" in condition and any(rf[\"factor\"].lower() in query_lower for rf in condition[\"risk_factors\"]):\n",
    "                        relevant_info.append(\"\\n**Risk Factors:**\")\n",
    "                        for rf in condition[\"risk_factors\"]:\n",
    "                            if rf[\"factor\"].lower() in query_lower:\n",
    "                                relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                    # Include diagnostic criteria (simplified)\n",
    "                    if \"diagnostic_criteria\" in condition and \"diagnose\" in query_lower:\n",
    "                        tests = \", \".join(condition[\"diagnostic_criteria\"].get(\"tests\", []))\n",
    "                        thresholds = \", \".join([f\"{k} {v}\" for k, v in condition[\"diagnostic_criteria\"].get(\"diagnostic_thresholds\", {}).items()])\n",
    "                        if tests or thresholds:\n",
    "                            relevant_info.append(f\"\\n**Diagnosis:** It is diagnosed using tests like {tests} and thresholds such as {thresholds}.\")\n",
    "                    # Include treatment pathways\n",
    "                    if \"treatment_pathways\" in condition and \"treat\" in query_lower:\n",
    "                        treatment_info = \"\\n**Treatment Pathways:**\\n\"\n",
    "                        for stage in condition[\"treatment_pathways\"]:\n",
    "                            actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                            treatment_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                        relevant_info.append(treatment_info)\n",
    "                    break  # Assuming we want info about one condition at a time\n",
    "\n",
    "            # General questions about risk factors\n",
    "            if \"risk factors for\" in query_lower:\n",
    "                for condition in data[\"medical_conditions\"]:\n",
    "                    if condition[\"name\"].lower() in query_lower:\n",
    "                        relevant_info.append(f\"Risk factors for {condition['name']} (Health) include:\")\n",
    "                        for rf in condition.get(\"risk_factors\", []):\n",
    "                            relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                        break\n",
    "\n",
    "        elif category == \"career\":\n",
    "            # Check for specific career opportunities\n",
    "            for career in data[\"career_opportunities\"]:\n",
    "                if career[\"name\"].lower() in query_lower:\n",
    "                    relevant_info.append(f\"Regarding {career['name']} (Career):\")\n",
    "                    # Include career pathways\n",
    "                    if \"career_pathways\" in career and \"pathways\" in query_lower:\n",
    "                        relevant_info.append(\"\\n**Career Pathways:**\")\n",
    "                        for cp in career[\"career_pathways\"]:\n",
    "                            relevant_info.append(f\"- {cp['factor']}: {cp['explanation']}\")\n",
    "                    # Include entry requirements\n",
    "                    if \"entry requirements\" in query_lower or \"requirements for\" in query_lower:\n",
    "                        if \"career_progression_criteria\" in career and \"entry_requirements\" in career[\"career_progression_criteria\"]:\n",
    "                            requirements = \", \".join(career[\"career_progression_criteria\"][\"entry_requirements\"])\n",
    "                            relevant_info.append(f\"\\n**Entry Requirements:** {requirements}\")\n",
    "                    # Include advancement pathways\n",
    "                    if \"advancement\" in query_lower or \"progression\" in query_lower:\n",
    "                        if \"advancement_pathways\" in career:\n",
    "                            advancement_info = \"\\n**Advancement Pathways:**\\n\"\n",
    "                            for stage in career[\"advancement_pathways\"]:\n",
    "                                actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                                advancement_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                            relevant_info.append(advancement_info)\n",
    "                    break\n",
    "\n",
    "        elif category == \"relationship\":\n",
    "            # Check for specific relationship types\n",
    "            for relationship in data[\"relationship_types\"]:\n",
    "                if relationship[\"name\"].lower() in query_lower:\n",
    "                    relevant_info.append(f\"Regarding {relationship['name']} (Relationship):\")\n",
    "                    # Include relationship factors\n",
    "                    if \"relationship_factors\" in relationship and \"factors\" in query_lower:\n",
    "                        relevant_info.append(\"\\n**Relationship Factors:**\")\n",
    "                        for rf in relationship[\"relationship_factors\"]:\n",
    "                            relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                    # Include development pathways\n",
    "                    if \"development\" in query_lower or \"building\" in query_lower:\n",
    "                        if \"relationship_development_pathways\" in relationship:\n",
    "                            development_info = \"\\n**Development Pathways:**\\n\"\n",
    "                            for stage in relationship[\"relationship_development_pathways\"]:\n",
    "                                actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                                development_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                            relevant_info.append(development_info)\n",
    "                    break\n",
    "\n",
    "        elif category == \"fitness\":\n",
    "            # Check for specific fitness questions\n",
    "            if \"fitness_data\" in data:  # Check if \"fitness_data\" key exists\n",
    "                for item in data[\"fitness_data\"]:  # Iterate through the array\n",
    "                    if item[\"question\"].lower() in query_lower:\n",
    "                        relevant_info.append(f\"Regarding {item['question']} (Fitness):\")\n",
    "                        # Include explanation\n",
    "                        if \"explanation\" in item:\n",
    "                            relevant_info.append(f\"\\n**Explanation:** {item['explanation']}\")\n",
    "                        # Include additional details\n",
    "                        if \"additional_details\" in item:\n",
    "                            relevant_info.append(\"\\n**Additional Details:**\")\n",
    "                            for key, value in item[\"additional_details\"].items():\n",
    "                                if isinstance(value, list):\n",
    "                                    relevant_info.append(f\"\\n{key.capitalize()}:\")\n",
    "                                    for detail in value:\n",
    "                                        if isinstance(detail, dict):\n",
    "                                            for sub_key, sub_value in detail.items():\n",
    "                                                relevant_info.append(f\"- {sub_key.capitalize()}: {sub_value}\")\n",
    "                                        else:\n",
    "                                            relevant_info.append(f\"- {detail}\")\n",
    "                                else:\n",
    "                                    relevant_info.append(f\"\\n{key.capitalize()}: {value}\")\n",
    "                        break\n",
    "\n",
    "    return \"\\n\".join(relevant_info)\n",
    "\n",
    "def explain_response_all(user_input, all_data):\n",
    "    relevant_data = get_relevant_info_all(user_input, all_data)\n",
    "    if relevant_data:\n",
    "        prompt = f\"Explain the following question using the provided information, presented as a list with bullet points:\\n\\nQuestion: {user_input}\\n\\nRelevant Information:\\n{relevant_data}\\n\\nExplanation:\"\n",
    "    else:\n",
    "        prompt = f\"Explain the following question using bullet points:\\n\\nQuestion:{user_input}\\n\\nExplanation:\"\n",
    "\n",
    "    raw_response = query_llama_2_api(prompt)\n",
    "    explanation = format_explanation(user_input, raw_response)\n",
    "    return explanation\n",
    "\n",
    "def chat():\n",
    "    print(\"\\nðŸ¤– AI Chatbot: Hello! Ask me anything about health, career, relationships, or fitness, and I'll explain my answers in detail. Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"\\nðŸ¤– AI: Goodbye! Have a great day!\\n\")\n",
    "            break\n",
    "        response = explain_response_all(user_input, all_data)\n",
    "        print(\"\\nðŸ¤– AI:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AI Chatbot: Hello! Ask me anything about health, career, relationships, or fitness, and I'll explain my answers in detail. Type 'exit' to stop.\n",
      "\n",
      "Error loading or running Qwen: The checkpoint you are trying to load has model type `qwen2_5_omni` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.\n",
      "\n",
      "You can update Transformers with the command `pip install --upgrade transformers`. If this does not work, and the checkpoint is very new, then there may not be a release version that supports this model yet. In this case, you can get the most up-to-date code by installing Transformers from source with the command `pip install git+https://github.com/huggingface/transformers.git`\n",
      "\n",
      "ðŸ¤– AI: ðŸ¤– AI Explanation for your query: 'What skills do I need to learn or improve to advance in my career?'\n",
      "\n",
      "Could not generate a response. \n",
      "\n",
      "\n",
      "ðŸ¤– AI: Goodbye! Have a great day!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "\n",
    "# --- Load JSON Datasets ---\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "health_data = load_json('health_data.json')\n",
    "career_data = load_json('career_data.json')\n",
    "relationship_data = load_json('relationship_data.json')\n",
    "fitness_data = load_json('fitness_data.json')\n",
    "\n",
    "all_data = {\n",
    "    \"health\": health_data,\n",
    "    \"career\": career_data,\n",
    "    \"relationship\": relationship_data,\n",
    "    \"fitness\": fitness_data\n",
    "}\n",
    "\n",
    "# --- Qwen-2.5-Omni-7B API Integration ---\n",
    "def query_qwen_api(prompt, model_name=\"Qwen/Qwen2.5-Omni-7B\"):\n",
    "    \"\"\"Generate response using Qwen-2.5-Omni-7B with 4-bit quantization.\"\"\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            load_in_4bit=True,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        outputs = model.generate(**inputs, max_length=1000)\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or running Qwen: {e}\")\n",
    "        return \"Could not generate a response.\"\n",
    "\n",
    "def format_explanation(user_input, raw_explanation):\n",
    "    explanation = f\"ðŸ¤– AI Explanation for your query: '{user_input}'\\n\\n\"\n",
    "    if raw_explanation:\n",
    "        explanation += raw_explanation.strip()\n",
    "    else:\n",
    "        explanation += \"The AI could not generate an explanation.\"\n",
    "    return explanation\n",
    "\n",
    "def get_relevant_info_all(query, all_data):\n",
    "    query_lower = query.lower()\n",
    "    relevant_info = []\n",
    "\n",
    "    for category, data in all_data.items():\n",
    "        if category == \"health\":\n",
    "            # Check for specific conditions\n",
    "            for condition in data[\"medical_conditions\"]:\n",
    "                if condition[\"name\"].lower() in query_lower:\n",
    "                    relevant_info.append(f\"Regarding {condition['name']} (Health):\")\n",
    "                    # Include risk factors\n",
    "                    if \"risk_factors\" in condition and any(rf[\"factor\"].lower() in condition[\"risk_factors\"]):\n",
    "                        relevant_info.append(\"\\n**Risk Factors:**\")\n",
    "                        for rf in condition[\"risk_factors\"]:\n",
    "                            if rf[\"factor\"].lower() in condition[\"risk_factors\"]:\n",
    "                                relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                    # Include diagnostic criteria (simplified)\n",
    "                    if \"diagnostic_criteria\" in condition and \"diagnose\" in query_lower:\n",
    "                        tests = \", \".join(condition[\"diagnostic_criteria\"].get(\"tests\", []))\n",
    "                        thresholds = \", \".join([f\"{k} {v}\" for k, v in condition[\"diagnostic_criteria\"].get(\"diagnostic_thresholds\", {}).items()])\n",
    "                        if tests or thresholds:\n",
    "                            relevant_info.append(f\"\\n**Diagnosis:** It is diagnosed using tests like {tests} and thresholds such as {thresholds}.\")\n",
    "                    # Include treatment pathways\n",
    "                    if \"treatment_pathways\" in condition and \"treat\" in query_lower:\n",
    "                        treatment_info = \"\\n**Treatment Pathways:**\\n\"\n",
    "                        for stage in condition[\"treatment_pathways\"]:\n",
    "                            actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                            treatment_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                        relevant_info.append(treatment_info)\n",
    "                    break  # Assuming we want info about one condition at a time\n",
    "\n",
    "            # General questions about risk factors\n",
    "            if \"risk factors for\" in query_lower:\n",
    "                for condition in data[\"medical_conditions\"]:\n",
    "                    if condition[\"name\"].lower() in query_lower:\n",
    "                        relevant_info.append(f\"Risk factors for {condition['name']} (Health) include:\")\n",
    "                        for rf in condition.get(\"risk_factors\", []):\n",
    "                            relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                        break\n",
    "\n",
    "        elif category == \"career\":\n",
    "            # Check for specific career opportunities\n",
    "            for career in data[\"career_opportunities\"]:\n",
    "                if career[\"name\"].lower() in query_lower:\n",
    "                    relevant_info.append(f\"Regarding {career['name']} (Career):\")\n",
    "                    # Include career pathways\n",
    "                    if \"career_pathways\" in career and \"pathways\" in query_lower:\n",
    "                        relevant_info.append(\"\\n**Career Pathways:**\")\n",
    "                        for cp in career[\"career_pathways\"]:\n",
    "                            relevant_info.append(f\"- {cp['factor']}: {cp['explanation']}\")\n",
    "                    # Include entry requirements\n",
    "                    if \"entry requirements\" in query_lower or \"requirements for\" in query_lower:\n",
    "                        if \"career_progression_criteria\" in career and \"entry_requirements\" in career[\"career_progression_criteria\"]:\n",
    "                            requirements = \", \".join(career[\"career_progression_criteria\"][\"entry_requirements\"])\n",
    "                            relevant_info.append(f\"\\n**Entry Requirements:** {requirements}\")\n",
    "                    # Include advancement pathways\n",
    "                    if \"advancement\" in query_lower or \"progression\" in query_lower:\n",
    "                        if \"advancement_pathways\" in career:\n",
    "                            advancement_info = \"\\n**Advancement Pathways:**\\n\"\n",
    "                            for stage in career[\"advancement_pathways\"]:\n",
    "                                actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                                advancement_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                            relevant_info.append(advancement_info)\n",
    "                    break\n",
    "\n",
    "        elif category == \"relationship\":\n",
    "            # Check for specific relationship types\n",
    "            for relationship in data[\"relationship_types\"]:\n",
    "                if relationship[\"name\"].lower() in query_lower:\n",
    "                    relevant_info.append(f\"Regarding {relationship['name']} (Relationship):\")\n",
    "                    # Include relationship factors\n",
    "                    if \"relationship_factors\" in relationship and \"factors\" in query_lower:\n",
    "                        relevant_info.append(\"\\n**Relationship Factors:**\")\n",
    "                        for rf in relationship[\"relationship_factors\"]:\n",
    "                            relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                    # Include development pathways\n",
    "                    if \"development\" in query_lower or \"building\" in query_lower:\n",
    "                        if \"relationship_development_pathways\" in relationship:\n",
    "                            development_info = \"\\n**Development Pathways:**\\n\"\n",
    "                            for stage in relationship[\"relationship_development_pathways\"]:\n",
    "                                actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                                development_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                            relevant_info.append(development_info)\n",
    "                    break\n",
    "\n",
    "        elif category == \"fitness\":\n",
    "            # Check for specific fitness questions\n",
    "            if \"fitness_data\" in data:  # Check if \"fitness_data\" key exists\n",
    "                for item in data[\"fitness_data\"]:  # Iterate through the array\n",
    "                    if item[\"question\"].lower() in query_lower:\n",
    "                        relevant_info.append(f\"Regarding {item['question']} (Fitness):\")\n",
    "                        # Include explanation\n",
    "                        if \"explanation\" in item:\n",
    "                            relevant_info.append(f\"\\n**Explanation:** {item['explanation']}\")\n",
    "                        # Include additional details\n",
    "                        if \"additional_details\" in item:\n",
    "                            relevant_info.append(\"\\n**Additional Details:**\")\n",
    "                            for key, value in item[\"additional_details\"].items():\n",
    "                                if isinstance(value, list):\n",
    "                                    relevant_info.append(f\"\\n{key.capitalize()}:\")\n",
    "                                    for detail in value:\n",
    "                                        if isinstance(detail, dict):\n",
    "                                            for sub_key, sub_value in detail.items():\n",
    "                                                relevant_info.append(f\"- {sub_key.capitalize()}: {sub_value}\")\n",
    "                                        else:\n",
    "                                            relevant_info.append(f\"- {detail}\")\n",
    "                                else:\n",
    "                                    relevant_info.append(f\"\\n{key.capitalize()}: {value}\")\n",
    "                        break\n",
    "\n",
    "    return \"\\n\".join(relevant_info)\n",
    "\n",
    "def explain_response_all(user_input, all_data):\n",
    "    relevant_data = get_relevant_info_all(user_input, all_data)\n",
    "    if relevant_data:\n",
    "        prompt = f\"Explain the following question using the provided information, presented as a list with bullet points:\\n\\nQuestion: {user_input}\\n\\nRelevant Information:\\n{relevant_data}\\n\\nExplanation:\"\n",
    "    else:\n",
    "        prompt = f\"Explain the following question using bullet points:\\n\\nQuestion: {user_input}\\n\\nExplanation:\"\n",
    "\n",
    "    raw_response = query_qwen_api(prompt)\n",
    "    explanation = format_explanation(user_input, raw_response)\n",
    "    return explanation\n",
    "\n",
    "def chat():\n",
    "    print(\"\\nðŸ¤– AI Chatbot: Hello! Ask me anything about health, career, relationships, or fitness, and I'll explain my answers in detail. Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"\\nðŸ¤– AI: Goodbye! Have a great day!\\n\")\n",
    "            break\n",
    "        response = explain_response_all(user_input, all_data)\n",
    "        print(\"\\nðŸ¤– AI:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AI Chatbot: Hello! Ask me anything about health, career, relationships, or fitness, and I'll explain my answers in detail. Type 'exit' to stop.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-R1:\n",
      "- configuration_deepseek.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-R1:\n",
      "- modeling_deepseek.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading or running DeepSeek-R1: Using `low_cpu_mem_usage=True`, a `device_map` or a `tp_plan` requires Accelerate: `pip install 'accelerate>=0.26.0'`\n",
      "\n",
      "ðŸ¤– AI: ðŸ¤– AI Explanation for your query: 'What skills do I need to learn or improve to advance in my career?'\n",
      "\n",
      "Could not generate a response. \n",
      "\n",
      "\n",
      "ðŸ¤– AI: Goodbye! Have a great day!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "\n",
    "# --- Load JSON Datasets ---\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "health_data = load_json('health_data.json')\n",
    "career_data = load_json('career_data.json')\n",
    "relationship_data = load_json('relationship_data.json')\n",
    "fitness_data = load_json('fitness_data.json')\n",
    "\n",
    "all_data = {\n",
    "    \"health\": health_data,\n",
    "    \"career\": career_data,\n",
    "    \"relationship\": relationship_data,\n",
    "    \"fitness\": fitness_data\n",
    "}\n",
    "\n",
    "# --- DeepSeek-R1 API Integration ---\n",
    "def query_deepseek_r1_api(prompt, model_name=\"deepseek-ai/DeepSeek-R1\"):\n",
    "    \"\"\"Generate response using DeepSeek-R1 with 4-bit quantization.\"\"\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            load_in_4bit=True,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        outputs = model.generate(**inputs, max_length=1000)\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or running DeepSeek-R1: {e}\")\n",
    "        return \"Could not generate a response.\"\n",
    "\n",
    "def format_explanation(user_input, raw_explanation):\n",
    "    explanation = f\"ðŸ¤– AI Explanation for your query: '{user_input}'\\n\\n\"\n",
    "    if raw_explanation:\n",
    "        explanation += raw_explanation.strip()\n",
    "    else:\n",
    "        explanation += \"The AI could not generate an explanation.\"\n",
    "    return explanation\n",
    "\n",
    "def get_relevant_info_all(query, all_data):\n",
    "    query_lower = query.lower()\n",
    "    relevant_info = []\n",
    "\n",
    "    for category, data in all_data.items():\n",
    "        if category == \"health\":\n",
    "            # Check for specific conditions\n",
    "            for condition in data[\"medical_conditions\"]:\n",
    "                if condition[\"name\"].lower() in query_lower:\n",
    "                    relevant_info.append(f\"Regarding {condition['name']} (Health):\")\n",
    "                    # Include risk factors\n",
    "                    if \"risk_factors\" in condition and any(rf[\"factor\"].lower() in condition[\"risk_factors\"]):\n",
    "                        relevant_info.append(\"\\n**Risk Factors:**\")\n",
    "                        for rf in condition[\"risk_factors\"]:\n",
    "                            if rf[\"factor\"].lower() in condition[\"risk_factors\"]:\n",
    "                                relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                    # Include diagnostic criteria (simplified)\n",
    "                    if \"diagnostic_criteria\" in condition and \"diagnose\" in query_lower:\n",
    "                        tests = \", \".join(condition[\"diagnostic_criteria\"].get(\"tests\", []))\n",
    "                        thresholds = \", \".join([f\"{k} {v}\" for k, v in condition[\"diagnostic_criteria\"].get(\"diagnostic_thresholds\", {}).items()])\n",
    "                        if tests or thresholds:\n",
    "                            relevant_info.append(f\"\\n**Diagnosis:** It is diagnosed using tests like {tests} and thresholds such as {thresholds}.\")\n",
    "                    # Include treatment pathways\n",
    "                    if \"treatment_pathways\" in condition and \"treat\" in query_lower:\n",
    "                        treatment_info = \"\\n**Treatment Pathways:**\\n\"\n",
    "                        for stage in condition[\"treatment_pathways\"]:\n",
    "                            actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                            treatment_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                        relevant_info.append(treatment_info)\n",
    "                    break  # Assuming we want info about one condition at a time\n",
    "\n",
    "            # General questions about risk factors\n",
    "            if \"risk factors for\" in query_lower:\n",
    "                for condition in data[\"medical_conditions\"]:\n",
    "                    if condition[\"name\"].lower() in query_lower:\n",
    "                        relevant_info.append(f\"Risk factors for {condition['name']} (Health) include:\")\n",
    "                        for rf in condition.get(\"risk_factors\", []):\n",
    "                            relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                        break\n",
    "\n",
    "        elif category == \"career\":\n",
    "            # Check for specific career opportunities\n",
    "            for career in data[\"career_opportunities\"]:\n",
    "                if career[\"name\"].lower() in query_lower:\n",
    "                    relevant_info.append(f\"Regarding {career['name']} (Career):\")\n",
    "                    # Include career pathways\n",
    "                    if \"career_pathways\" in career and \"pathways\" in query_lower:\n",
    "                        relevant_info.append(\"\\n**Career Pathways:**\")\n",
    "                        for cp in career[\"career_pathways\"]:\n",
    "                            relevant_info.append(f\"- {cp['factor']}: {cp['explanation']}\")\n",
    "                    # Include entry requirements\n",
    "                    if \"entry requirements\" in query_lower or \"requirements for\" in query_lower:\n",
    "                        if \"career_progression_criteria\" in career and \"entry_requirements\" in career[\"career_progression_criteria\"]:\n",
    "                            requirements = \", \".join(career[\"career_progression_criteria\"][\"entry_requirements\"])\n",
    "                            relevant_info.append(f\"\\n**Entry Requirements:** {requirements}\")\n",
    "                    # Include advancement pathways\n",
    "                    if \"advancement\" in query_lower or \"progression\" in query_lower:\n",
    "                        if \"advancement_pathways\" in career:\n",
    "                            advancement_info = \"\\n**Advancement Pathways:**\\n\"\n",
    "                            for stage in career[\"advancement_pathways\"]:\n",
    "                                actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                                advancement_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                            relevant_info.append(advancement_info)\n",
    "                    break\n",
    "\n",
    "        elif category == \"relationship\":\n",
    "            # Check for specific relationship types\n",
    "            for relationship in data[\"relationship_types\"]:\n",
    "                if relationship[\"name\"].lower() in query_lower:\n",
    "                    relevant_info.append(f\"Regarding {relationship['name']} (Relationship):\")\n",
    "                    # Include relationship factors\n",
    "                    if \"relationship_factors\" in relationship and \"factors\" in query_lower:\n",
    "                        relevant_info.append(\"\\n**Relationship Factors:**\")\n",
    "                        for rf in relationship[\"relationship_factors\"]:\n",
    "                            relevant_info.append(f\"- {rf['factor']}: {rf['explanation']}\")\n",
    "                    # Include development pathways\n",
    "                    if \"development\" in query_lower or \"building\" in query_lower:\n",
    "                        if \"relationship_development_pathways\" in relationship:\n",
    "                            development_info = \"\\n**Development Pathways:**\\n\"\n",
    "                            for stage in relationship[\"relationship_development_pathways\"]:\n",
    "                                actions = \", \".join(stage.get(\"recommended_actions\", []))\n",
    "                                development_info += f\"- {stage['stage']}: {actions}\\n\"\n",
    "                            relevant_info.append(development_info)\n",
    "                    break\n",
    "\n",
    "        elif category == \"fitness\":\n",
    "            # Check for specific fitness questions\n",
    "            if \"fitness_data\" in data:  # Check if \"fitness_data\" key exists\n",
    "                for item in data[\"fitness_data\"]:  # Iterate through the array\n",
    "                    if item[\"question\"].lower() in query_lower:\n",
    "                        relevant_info.append(f\"Regarding {item['question']} (Fitness):\")\n",
    "                        # Include explanation\n",
    "                        if \"explanation\" in item:\n",
    "                            relevant_info.append(f\"\\n**Explanation:** {item['explanation']}\")\n",
    "                        # Include additional details\n",
    "                        if \"additional_details\" in item:\n",
    "                            relevant_info.append(\"\\n**Additional Details:**\")\n",
    "                            for key, value in item[\"additional_details\"].items():\n",
    "                                if isinstance(value, list):\n",
    "                                    relevant_info.append(f\"\\n{key.capitalize()}:\")\n",
    "                                    for detail in value:\n",
    "                                        if isinstance(detail, dict):\n",
    "                                            for sub_key, sub_value in detail.items():\n",
    "                                                relevant_info.append(f\"- {sub_key.capitalize()}: {sub_value}\")\n",
    "                                        else:\n",
    "                                            relevant_info.append(f\"- {detail}\")\n",
    "                                else:\n",
    "                                    relevant_info.append(f\"\\n{key.capitalize()}: {value}\")\n",
    "                        break\n",
    "\n",
    "    return \"\\n\".join(relevant_info)\n",
    "\n",
    "def explain_response_all(user_input, all_data):\n",
    "    relevant_data = get_relevant_info_all(user_input, all_data)\n",
    "    if relevant_data:\n",
    "        prompt = f\"Explain the following question using the provided information, presented as a list with bullet points:\\n\\nQuestion: {user_input}\\n\\nRelevant Information:\\n{relevant_data}\\n\\nExplanation:\"\n",
    "    else:\n",
    "        prompt = f\"Explain the following question using bullet points:\\n\\nQuestion: {user_input}\\n\\nExplanation:\"\n",
    "\n",
    "    raw_response = query_deepseek_r1_api(prompt)\n",
    "    explanation = format_explanation(user_input, raw_response)\n",
    "    return explanation\n",
    "\n",
    "def chat():\n",
    "    print(\"\\nðŸ¤– AI Chatbot: Hello! Ask me anything about health, career, relationships, or fitness, and I'll explain my answers in detail. Type 'exit' to stop.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"\\nðŸ¤– AI: Goodbye! Have a great day!\\n\")\n",
    "            break\n",
    "        response = explain_response_all(user_input, all_data)\n",
    "        print(\"\\nðŸ¤– AI:\", response, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting scipy (from bitsandbytes)\n",
      "  Using cached scipy-1.15.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /opt/homebrew/Caskroom/miniconda/base/envs/jupyter_env/lib/python3.11/site-packages (from scipy->bitsandbytes) (2.0.1)\n",
      "Using cached bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "Downloading scipy-1.15.2-cp311-cp311-macosx_14_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy, bitsandbytes\n",
      "Successfully installed bitsandbytes-0.42.0 scipy-1.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes --prefer-binary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM2vgOAZFEpKWBI4MY9NDTZ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
